{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XZp4Be3z4eJA"
      },
      "source": [
        "# DSC530-T302\n",
        "# Weeks 3-4 Assignment\n",
        "# Jacob Siau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W58yhTdztMCt"
      },
      "source": [
        "## Chapter 1 Exercises 4-8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 4.\n",
        "\n",
        "Run the code in the first cell of the exercises.ipynb notebook. It will give you a list of 100 values to work with for the rest of the exercises in this chapter. Be sure to treat these values as a sample of the population."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "import random\n",
        "from collections import Counter\n",
        "import statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "random.seed(0)\n",
        "salaries = [round(random.random()*1000000, -3) for _ in range(100)]\n",
        "# Currently, this code generated a list of random values as salaries for this exercise."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 5.\n",
        "Using the data from Exercise 4, calculate the following statistics without importing anything from the statistics module (Python Statistics) in the Python standard library, and then confirm your results match up to those that are obtained when using the statistics module (where possible):\n",
        "\n",
        "Mean,\n",
        "Median,\n",
        "Mode,\n",
        "Sample variance,\n",
        "Sample standard deviation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean: 585690.0\n",
            "Median: 589000.0\n",
            "Mode: 477000.0\n",
            "Sample Variance: 70664054444.44444\n",
            "Sample Standard Deviation: 265827.11382484\n",
            "\n",
            "--- Confirmation with statistics module ---\n",
            "Mean: 585690.0\n",
            "Median: 589000.0\n",
            "Mode: 477000.0\n",
            "Sample Variance: 70664054444.44444\n",
            "Sample Standard Deviation: 265827.11382484\n"
          ]
        }
      ],
      "source": [
        "# Calculate statistics without using statistics module\n",
        "n = len(salaries)\n",
        "\n",
        "# Mean\n",
        "mean = sum(salaries) / n\n",
        "\n",
        "# Median\n",
        "sorted_salaries = sorted(salaries)\n",
        "if n % 2 == 0:\n",
        "    median = (sorted_salaries[n//2 - 1] + sorted_salaries[n//2]) / 2\n",
        "else:\n",
        "    median = sorted_salaries[n//2]\n",
        "\n",
        "# Mode\n",
        "salary_counts = {}\n",
        "for salary in salaries:\n",
        "    if salary in salary_counts:\n",
        "        salary_counts[salary] += 1\n",
        "    else:\n",
        "        salary_counts[salary] = 1\n",
        "mode = max(salary_counts, key=salary_counts.get)\n",
        "\n",
        "# Sample variance\n",
        "sample_variance = sum((x - mean) ** 2 for x in salaries) / (n - 1)\n",
        "\n",
        "# Sample standard deviation\n",
        "sample_std_dev = sample_variance ** 0.5\n",
        "\n",
        "print(f\"Mean: {mean}\")\n",
        "print(f\"Median: {median}\")\n",
        "print(f\"Mode: {mode}\")\n",
        "print(f\"Sample Variance: {sample_variance}\")\n",
        "print(f\"Sample Standard Deviation: {sample_std_dev}\")\n",
        "\n",
        "# Confirm with statistics module\n",
        "print(\"\\n--- Confirmation with statistics module ---\")\n",
        "print(f\"Mean: {statistics.mean(salaries)}\")\n",
        "print(f\"Median: {statistics.median(salaries)}\")\n",
        "print(f\"Mode: {statistics.mode(salaries)}\")\n",
        "print(f\"Sample Variance: {statistics.variance(salaries)}\")\n",
        "print(f\"Sample Standard Deviation: {statistics.stdev(salaries)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 6.\n",
        "Using the data from Exercise 4, calculate the following statistics using the functions in the statistics module where appropriate:\n",
        "\n",
        "Range,\n",
        "Coefficient of variation,\n",
        "Interquartile range,\n",
        "Quartile coefficient of dispersion"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Range: 995000.0\n",
            "Coefficient of Variation: 45.39%\n",
            "Interquartile Range: 421750.0\n",
            "Quartile Coefficient of Dispersion: 0.3449\n"
          ]
        }
      ],
      "source": [
        "# Range\n",
        "range_val = max(salaries) - min(salaries)\n",
        "\n",
        "# Coefficient of variation\n",
        "coefficient_of_variation = (sample_std_dev / mean) * 100\n",
        "\n",
        "# Interquartile range\n",
        "q1 = statistics.quantiles(salaries, n=4)[0]\n",
        "q3 = statistics.quantiles(salaries, n=4)[2]\n",
        "iqr = q3 - q1\n",
        "\n",
        "# Quartile coefficient of dispersion\n",
        "quartile_coefficient_of_dispersion = (q3 - q1) / (q3 + q1)\n",
        "\n",
        "print(f\"Range: {range_val}\")\n",
        "print(f\"Coefficient of Variation: {coefficient_of_variation:.2f}%\")\n",
        "print(f\"Interquartile Range: {iqr}\")\n",
        "print(f\"Quartile Coefficient of Dispersion: {quartile_coefficient_of_dispersion:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 7.\n",
        "Scale the data created in Exercise 4 using the following strategies:\n",
        "\n",
        "Min-max scaling (normalizing),\n",
        "Standardizing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Min-max scaled (normalized) salaries:\n",
            "[0.8472361809045226, 0.7608040201005025, 0.4221105527638191, 0.2592964824120603, 0.5125628140703518, 0.40603015075376886, 0.7869346733668342, 0.3035175879396985, 0.47839195979899496, 0.5849246231155779, 0.9115577889447236, 0.5065326633165829, 0.28241206030150756, 0.7587939698492462, 0.6201005025125628, 0.25125628140703515, 0.91356783919598, 0.9869346733668342, 0.8130653266331658, 0.9055276381909547, 0.31055276381909547, 0.7326633165829146, 0.9025125628140703, 0.6864321608040201, 0.4733668341708543, 0.10050251256281408, 0.43517587939698493, 0.6130653266331658, 0.9165829145728643, 0.9708542713567839, 0.47839195979899496, 0.8683417085427135, 0.26030150753768844, 0.8080402010050252, 0.5507537688442211, 0.01306532663316583, 0.7226130653266332, 0.4, 0.828140703517588, 0.6703517587939698, 0.0, 0.49547738693467336, 0.871356783919598, 0.2442211055276382, 0.3256281407035176, 0.8733668341708543, 0.19095477386934673, 0.5698492462311557, 0.23919597989949748, 0.9718592964824121, 0.8060301507537688, 0.4492462311557789, 0.07939698492462312, 0.32060301507537686, 0.5095477386934674, 0.9366834170854271, 0.10854271356783919, 0.5527638190954773, 0.7095477386934673, 0.5487437185929648, 0.8170854271356784, 0.5417085427135678, 0.9678391959798995, 0.6050251256281407, 0.5899497487437186, 0.4462311557788945, 0.5979899497487438, 0.385929648241206, 0.5778894472361809, 0.2904522613065327, 0.18894472361809045, 0.18693467336683417, 0.6150753768844222, 0.6592964824120603, 0.47839195979899496, 0.08944723618090453, 0.7608040201005025, 0.8804020100502512, 0.9266331658291457, 0.8452261306532663, 0.9015075376884422, 0.9266331658291457, 0.542713567839196, 0.39195979899497485, 0.7075376884422111, 0.27638190954773867, 0.8150753768844221, 0.8522613065326633, 0.8984924623115578, 0.5919597989949749, 0.9537688442211055, 0.5819095477386935, 0.45226130653266333, 0.6623115577889447, 1.0, 0.9206030150753769, 0.7959798994974875, 0.0814070351758794, 0.6150753768844222, 0.48743718592964824]\n",
            "\n",
            "Standardized salaries:\n",
            "[0.9717217942267801, 0.6482032533127501, -0.6195380058503674, -1.228956652688424, -0.28097209094033604, -0.6797275018343729, 0.7460111842867592, -1.0634355387324086, -0.40887476990634786, -0.010119359012310937, 1.2124797781628023, -0.3035431519343381, -1.142434252211416, 0.6406795663147493, 0.12154516345270126, -1.2590514006804265, 1.220003465160803, 1.4946180405878284, 0.8438191152607681, 1.1899087171688003, -1.037102634239406, 0.5428716353407403, 1.178623186671799, 0.36982683438672426, -0.4276839874013496, -1.8233279255304788, -0.5706340403633628, 0.09521225895969881, 1.2312889956578041, 1.434428544603823, -0.40887476990634786, 1.0507205077057873, -1.2251948091894236, 0.8250098977657664, -0.1380220379783228, -2.150608309943509, 0.5052532003507368, -0.7022985628283751, 0.9002467677457734, 0.3096373384027187, -2.199512275430514, -0.34492343042334195, 1.0620060382027885, -1.285384305173429, -0.9806749817544008, 1.0695297252007891, -1.4847620106204475, -0.06654701149731616, -1.304193522668431, 1.4381903881028233, 0.8174862107677657, -0.517968231377358, -1.9023266390094862, -0.9994841992494026, -0.2922576214373371, 1.3065258656378111, -1.7932331775384762, -0.1304983509803221, 0.4563492348637323, -0.14554572497632348, 0.8588664892567696, -0.17187862946932592, 1.4231430141068218, 0.06511751096769604, 0.008689858482690806, -0.529253761874359, 0.038784606474693596, -0.7549643718143799, -0.03645226350531338, -1.112339504219413, -1.4922856976184482, -1.4998093846164489, 0.10273594595769951, 0.26825705991371485, -0.40887476990634786, -1.8647082040194827, 0.6482032533127501, 1.0958626296937914, 1.2689074306478076, 0.9641981072287793, 1.1748613431727988, 1.2689074306478076, -0.16811678597032556, -0.7323933108203778, 0.4488255478657316, -1.165005313205418, 0.8513428022587689, 0.9905310117217818, 1.1635758126757978, 0.016213545480691503, 1.370477205120817, -0.02140488950931198, -0.5066827008803569, 0.2795425904107159, 1.543522006074833, 1.2463363696538055, 0.7798677757777622, -1.8948029520114855, 0.10273594595769951, -0.37501817841534474]\n"
          ]
        }
      ],
      "source": [
        "# Min-max scaling (normalizing)\n",
        "min_salary = min(salaries)\n",
        "max_salary = max(salaries)\n",
        "normalized_salaries = [(x - min_salary) / (max_salary - min_salary) for x in salaries]\n",
        "\n",
        "# Standardizing\n",
        "standardized_salaries = [(x - mean) / sample_std_dev for x in salaries]\n",
        "\n",
        "print(\"Min-max scaled (normalized) salaries:\")\n",
        "print(normalized_salaries)\n",
        "print(\"\\nStandardized salaries:\")\n",
        "print(standardized_salaries)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 8.\n",
        "Using the scaled data from Exercise 7, calculate the following:\n",
        "\n",
        "The covariance between the standardized and normalized data\n",
        "The Pearson correlation coefficient between the standardized and normalized data (this is 1, but due to rounding along the way, the result will be slightly less)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Covariance between standardized and normalized data: 0.267163\n",
            "Pearson correlation coefficient: 1.000000\n"
          ]
        }
      ],
      "source": [
        "# Covariance between standardized and normalized data\n",
        "n = len(standardized_salaries)\n",
        "mean_std = sum(standardized_salaries) / n\n",
        "mean_norm = sum(normalized_salaries) / n\n",
        "\n",
        "covariance = sum((standardized_salaries[i] - mean_std) * (normalized_salaries[i] - mean_norm) for i in range(n)) / (n - 1)\n",
        "\n",
        "# Pearson correlation coefficient\n",
        "std_dev_std = (sum((x - mean_std) ** 2 for x in standardized_salaries) / (n - 1)) ** 0.5\n",
        "std_dev_norm = (sum((x - mean_norm) ** 2 for x in normalized_salaries) / (n - 1)) ** 0.5\n",
        "\n",
        "pearson_correlation = covariance / (std_dev_std * std_dev_norm)\n",
        "\n",
        "print(f\"Covariance between standardized and normalized data: {covariance:.6f}\")\n",
        "print(f\"Pearson correlation coefficient: {pearson_correlation:.6f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Chapter 2 Exercises 1-6\n",
        "\n",
        "Using the data/parsed.csv file and the material from this chapter, complete the following exercises to practice your Pandas skills:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Exercise 1-6\n",
        "\n",
        "Find the 95th percentile of earthquake magnitude in Japan using the mb magnitude type.\n",
        "Find the percentage of earthquakes in Indonesia that were coupled with tsunamis.\n",
        "Calculate summary statistics for earthquakes in Nevada.\n",
        "Add a column indicating whether the earthquake happened in a country or US state that is on the Ring of Fire. Use Alaska, Antarctica (look for Antarctic), Bolivia, California, Canada, Chile, Costa Rica, Ecuador, Fiji, Guatemala, Indonesia, Japan, Kermadec Islands, Mexico (be careful not to select New Mexico), New Zealand, Peru, Philippines, Russia, Taiwan, Tonga, and Washington.\n",
        "Calculate the number of earthquakes in the Ring of Fire locations and the number outside of them.\n",
        "Find the tsunami count along the Ring of Fire."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. 95th percentile of earthquake magnitude in Japan (mb type): 4.9\n",
            "2. Percentage of earthquakes in Indonesia coupled with tsunamis: 23.12925170068027%\n",
            "3. Summary statistics for earthquakes in Nevada:\n",
            "count    681.000000\n",
            "mean       0.500073\n",
            "std        0.696710\n",
            "min       -0.500000\n",
            "25%       -0.100000\n",
            "50%        0.400000\n",
            "75%        0.900000\n",
            "max        2.900000\n",
            "Name: mag, dtype: float64\n",
            "5. Number of earthquakes in Ring of Fire locations: 7188\n",
            "5. Number of earthquakes outside Ring of Fire: 2144\n",
            "6. Tsunami count along the Ring of Fire: 45\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the earthquakes data\n",
        "df = pd.read_csv('data/parsed.csv')\n",
        "\n",
        "# 1. Find the 95th percentile of earthquake magnitude in Japan using the mb magnitude type\n",
        "japan_mb = df[(df['parsed_place'] == 'Japan') & (df['magType'] == 'mb')]\n",
        "percentile_95_japan = japan_mb['mag'].quantile(0.95)\n",
        "print(f\"1. 95th percentile of earthquake magnitude in Japan (mb type): {percentile_95_japan}\")\n",
        "\n",
        "# 2. Find the percentage of earthquakes in Indonesia that were coupled with tsunamis\n",
        "indonesia_quakes = df[df['parsed_place'] == 'Indonesia']\n",
        "indonesia_tsunami_pct = (indonesia_quakes['tsunami'].sum() / len(indonesia_quakes)) * 100\n",
        "print(f\"2. Percentage of earthquakes in Indonesia coupled with tsunamis: {indonesia_tsunami_pct}%\")\n",
        "\n",
        "# 3. Calculate summary statistics for earthquakes in Nevada\n",
        "nevada_quakes = df[df['parsed_place'] == 'Nevada']\n",
        "nevada_summary = nevada_quakes['mag'].describe()\n",
        "print(f\"3. Summary statistics for earthquakes in Nevada:\")\n",
        "print(nevada_summary)\n",
        "\n",
        "# 4. Add a column indicating whether the earthquake happened in a Ring of Fire location\n",
        "ring_of_fire_locations = [\n",
        "    'Alaska', 'Antarctic', 'Bolivia', 'California', 'Canada', 'Chile', \n",
        "    'Costa Rica', 'Ecuador', 'Fiji', 'Guatemala', 'Indonesia', 'Japan', \n",
        "    'Kermadec Islands', 'New Zealand', 'Peru', 'Philippines', 'Russia', \n",
        "    'Taiwan', 'Tonga', 'Washington'\n",
        "]\n",
        "\n",
        "# Look for Antarctic in place to match Antarctica, and Mexico to match Mexico (excluding New Mexico)\n",
        "def is_ring_of_fire(place):\n",
        "    if pd.isna(place):\n",
        "        return False\n",
        "    # Handle Mexico (exclude New Mexico)\n",
        "    if place == 'Mexico':\n",
        "        return True\n",
        "    # Handle Antarctic (matches Antarctica)\n",
        "    if 'Antarctic' in place:\n",
        "        return True\n",
        "    # Check other locations\n",
        "    return place in ring_of_fire_locations\n",
        "\n",
        "df['ring_of_fire'] = df['parsed_place'].apply(is_ring_of_fire)\n",
        "\n",
        "# 5. Calculate the number of earthquakes in the Ring of Fire locations and outside\n",
        "ring_of_fire_count = df['ring_of_fire'].sum()\n",
        "outside_ring_count = len(df) - ring_of_fire_count\n",
        "print(f\"5. Number of earthquakes in Ring of Fire locations: {ring_of_fire_count}\")\n",
        "print(f\"5. Number of earthquakes outside Ring of Fire: {outside_ring_count}\")\n",
        "\n",
        "# 6. Find the tsunami count along the Ring of Fire\n",
        "tsunami_ring_of_fire = df[df['ring_of_fire']]['tsunami'].sum()\n",
        "print(f\"6. Tsunami count along the Ring of Fire: {int(tsunami_ring_of_fire)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
